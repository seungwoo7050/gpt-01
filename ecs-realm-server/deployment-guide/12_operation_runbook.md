# 12. Operation Runbook - ìš´ì˜ ëŸ°ë¶

## ğŸ¯ ëª©í‘œ
ê²Œì„ ì„œë²„ ìš´ì˜ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ëª¨ë“  ìƒí™©ì— ëŒ€í•œ í‘œì¤€ ìš´ì˜ ì ˆì°¨(SOP)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ Prerequisites
- ìš´ì˜ í™˜ê²½ ì ‘ê·¼ ê¶Œí•œ
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì ‘ê·¼
- ê¸´ê¸‰ ì—°ë½ë§ êµ¬ì„±
- ë°±ì—…/ë³µêµ¬ ë„êµ¬
- ìš´ì˜ ìŠ¤í¬ë¦½íŠ¸

---

## 1. ì¼ìƒ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1.1 ì¼ì¼ ì ê²€ (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)
```bash
#!/bin/bash
# daily-check.sh

echo "=== Daily Health Check $(date) ==="

# 1. ì„œë²„ ìƒíƒœ í™•ì¸
echo "1. Checking server status..."
kubectl get pods -n game-production | grep -v Running
kubectl top nodes
kubectl top pods -n game-production

# 2. ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
echo "2. Checking database..."
mysql -h $DB_HOST -u admin -p$DB_PASS -e "
    SELECT 
        COUNT(*) as active_connections 
    FROM information_schema.processlist;
    
    SHOW STATUS LIKE 'Threads_connected';
    SHOW STATUS LIKE 'Slow_queries';
"

# 3. Redis ìƒíƒœ
echo "3. Checking Redis..."
redis-cli -h $REDIS_HOST INFO server
redis-cli -h $REDIS_HOST INFO memory
redis-cli -h $REDIS_HOST --latency

# 4. ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
echo "4. Checking disk usage..."
df -h | grep -E '(8[0-9]|9[0-9]|100)%'

# 5. ë¡œê·¸ ì—ëŸ¬ í™•ì¸
echo "5. Checking error logs..."
kubectl logs -n game-production -l app=game-server --since=24h | grep ERROR | wc -l

# 6. ì•Œë¦¼ í™•ì¸
echo "6. Checking alerts..."
curl -s http://alertmanager:9093/api/v1/alerts | jq '.data[] | select(.status.state=="active")'

echo "=== Check Complete ==="
```

### 1.2 ì£¼ê°„ ì ê²€ (ë§¤ì£¼ ì›”ìš”ì¼)
```yaml
weekly_tasks:
  - name: "ë°±ì—… ê²€ì¦"
    script: verify-backups.sh
    owner: ops-team
    
  - name: "ë³´ì•ˆ íŒ¨ì¹˜ í™•ì¸"
    script: check-security-updates.sh
    owner: security-team
    
  - name: "ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"
    script: generate-performance-report.sh
    owner: platform-team
    
  - name: "ìš©ëŸ‰ ê³„íš ê²€í† "
    script: capacity-planning.sh
    owner: infrastructure-team
    
  - name: "ì¸ì‹œë˜íŠ¸ ë¦¬ë·°"
    meeting: "Monday 2PM"
    participants: ["ops", "dev", "product"]
```

---

## 2. ì¸ì‹œë˜íŠ¸ ëŒ€ì‘

### 2.1 ì¸ì‹œë˜íŠ¸ ë ˆë²¨ ì •ì˜
| ë ˆë²¨ | ì„¤ëª… | ëŒ€ì‘ ì‹œê°„ | ì—ìŠ¤ì»¬ë ˆì´ì…˜ |
|------|------|-----------|--------------|
| P1 (Critical) | ì „ì²´ ì„œë¹„ìŠ¤ ë‹¤ìš´ | ì¦‰ì‹œ | CTO/VP |
| P2 (High) | ì£¼ìš” ê¸°ëŠ¥ ì¥ì•  | 15ë¶„ | Team Lead |
| P3 (Medium) | ì¼ë¶€ ê¸°ëŠ¥ ì €í•˜ | 1ì‹œê°„ | On-call |
| P4 (Low) | ë§ˆì´ë„ˆ ì´ìŠˆ | ì—…ë¬´ì‹œê°„ ë‚´ | Team |

### 2.2 ì¸ì‹œë˜íŠ¸ ëŒ€ì‘ í”Œë¡œìš°
```mermaid
graph TD
    A[ì¸ì‹œë˜íŠ¸ ë°œìƒ] --> B{ì‹¬ê°ë„ í‰ê°€}
    B -->|P1/P2| C[War Room ì†Œì§‘]
    B -->|P3/P4| D[ë‹´ë‹¹ì ì§€ì •]
    C --> E[ì¦‰ì‹œ ëŒ€ì‘]
    D --> F[ê³„íšëœ ëŒ€ì‘]
    E --> G[ì„ì‹œ ì¡°ì¹˜]
    F --> G
    G --> H[ê·¼ë³¸ ì›ì¸ ë¶„ì„]
    H --> I[ì˜êµ¬ í•´ê²°]
    I --> J[ì‚¬í›„ ë¶„ì„]
    J --> K[ë¬¸ì„œí™”]
```

### 2.3 War Room í”„ë¡œí† ì½œ
```markdown
## War Room ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì—­í•  ì§€ì •
- [ ] Incident Commander: ì „ì²´ ì§€íœ˜
- [ ] Technical Lead: ê¸°ìˆ ì  í•´ê²°
- [ ] Communications: ê³ ê°/ë‚´ë¶€ ì†Œí†µ
- [ ] Scribe: ê¸°ë¡ ë‹´ë‹¹

### ì´ˆê¸° ëŒ€ì‘ (0-15ë¶„)
- [ ] ì˜í–¥ ë²”ìœ„ íŒŒì•…
- [ ] ì„ì‹œ ì¡°ì¹˜ ì‹¤í–‰
- [ ] ì´í•´ê´€ê³„ì ì•Œë¦¼
- [ ] íƒ€ì„ë¼ì¸ ê¸°ë¡ ì‹œì‘

### ì§„í–‰ ì¤‘ (15ë¶„-í•´ê²°)
- [ ] 15ë¶„ë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸
- [ ] í•„ìš”ì‹œ ì¶”ê°€ ì¸ë ¥ ìš”ì²­
- [ ] ê³ ê° ê³µì§€ ë°œì†¡
- [ ] ë¡¤ë°± ì˜µì…˜ ê²€í† 

### í•´ê²° í›„
- [ ] ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸
- [ ] ëª¨ë‹ˆí„°ë§ ê°•í™”
- [ ] RCA ì¼ì • ì¡ê¸°
- [ ] ì´ˆê¸° ë¦¬í¬íŠ¸ ì‘ì„±
```

---

## 3. ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### 3.1 ì„œë²„ ë†’ì€ CPU ì‚¬ìš©ë¥ 
```bash
#!/bin/bash
# troubleshoot-high-cpu.sh

echo "=== High CPU Troubleshooting ==="

# 1. TOP í”„ë¡œì„¸ìŠ¤ í™•ì¸
echo "Top CPU consuming processes:"
kubectl exec -n game-production deployment/game-server -- top -b -n 1 | head -20

# 2. ìŠ¤ë ˆë“œ ë¤í”„
echo "Getting thread dump..."
kubectl exec -n game-production deployment/game-server -- kill -3 1
kubectl logs -n game-production deployment/game-server --tail=1000 > thread-dump.log

# 3. í”„ë¡œíŒŒì¼ë§ í™œì„±í™”
echo "Enabling profiling..."
kubectl exec -n game-production deployment/game-server -- curl -X POST http://localhost:9090/debug/pprof/profile?seconds=30 > cpu-profile.prof

# 4. ìë™ ìŠ¤ì¼€ì¼ë§ í™•ì¸
echo "Checking autoscaling status:"
kubectl get hpa -n game-production

# 5. ì„ì‹œ ì¡°ì¹˜
read -p "Scale up pods? (y/n) " -n 1 -r
if [[ $REPLY =~ ^[Yy]$ ]]; then
    kubectl scale deployment/game-server -n game-production --replicas=10
fi
```

### 3.2 ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ëŒ€ì‘
```bash
#!/bin/bash
# troubleshoot-memory-leak.sh

# 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl top pods -n game-production --containers

# 2. í™ ë¤í”„ ìƒì„±
POD=$(kubectl get pods -n game-production -l app=game-server -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n game-production $POD -- jmap -dump:format=b,file=/tmp/heap.hprof 1
kubectl cp game-production/$POD:/tmp/heap.hprof ./heap-$(date +%s).hprof

# 3. ë©”ëª¨ë¦¬ ë¶„ì„
echo "Analyzing memory..."
jhat -J-Xmx4g heap-*.hprof

# 4. ì¬ì‹œì‘ (ì„ì‹œ ì¡°ì¹˜)
kubectl rollout restart deployment/game-server -n game-production
```

### 3.3 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¬ë¡œìš° ì¿¼ë¦¬
```sql
-- slow-query-analysis.sql

-- í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬
SELECT 
    id,
    user,
    time,
    state,
    LEFT(info, 100) as query
FROM information_schema.processlist
WHERE time > 10
ORDER BY time DESC;

-- ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¡œê·¸ ë¶„ì„
SELECT 
    query_time,
    lock_time,
    rows_sent,
    rows_examined,
    LEFT(sql_text, 200) as query
FROM mysql.slow_log
WHERE query_time > 1
ORDER BY query_time DESC
LIMIT 20;

-- ì¸ë±ìŠ¤ ì‚¬ìš© í†µê³„
SELECT 
    table_schema,
    table_name,
    index_name,
    cardinality
FROM information_schema.statistics
WHERE table_schema = 'gamedb'
    AND cardinality = 0;

-- í…Œì´ë¸” ë½ í™•ì¸
SHOW OPEN TABLES WHERE In_use > 0;

-- ì„ì‹œ ì¡°ì¹˜: ë¬¸ì œ ì¿¼ë¦¬ ì¢…ë£Œ
-- KILL QUERY [process_id];
```

---

## 4. ì •ê¸° ìœ ì§€ë³´ìˆ˜

### 4.1 ê³„íšëœ ìœ ì§€ë³´ìˆ˜ ì ˆì°¨
```bash
#!/bin/bash
# planned-maintenance.sh

MAINTENANCE_START="2024-01-15 02:00:00"
MAINTENANCE_END="2024-01-15 04:00:00"

# 1. ì‚¬ì „ ê³µì§€ (24ì‹œê°„ ì „)
send_notification "Scheduled maintenance: $MAINTENANCE_START - $MAINTENANCE_END"

# 2. ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ í™œì„±í™”
kubectl patch configmap game-config -n game-production \
    -p '{"data":{"maintenance_mode":"true"}}'

# 3. ì‹ ê·œ ì ‘ì† ì°¨ë‹¨
kubectl patch service game-server -n game-production \
    -p '{"spec":{"selector":{"version":"maintenance"}}}'

# 4. ê¸°ì¡´ ì„¸ì…˜ ì¢…ë£Œ ëŒ€ê¸° (Graceful shutdown)
echo "Waiting for active sessions to complete..."
sleep 300

# 5. ë°±ì—… ìˆ˜í–‰
./backup-all.sh

# 6. ìœ ì§€ë³´ìˆ˜ ì‘ì—… ì‹¤í–‰
echo "Performing maintenance tasks..."
# - ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
mysql -h $DB_HOST -u admin -p$DB_PASS gamedb < optimize-tables.sql

# - ë¡œê·¸ ë¡œí…Œì´ì…˜
find /var/log/game-server -name "*.log" -mtime +30 -delete

# - ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
kubectl set image deployment/game-server game-server=$NEW_IMAGE -n game-production

# 7. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
kubectl rollout restart deployment/game-server -n game-production
kubectl rollout status deployment/game-server -n game-production

# 8. ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ í•´ì œ
kubectl patch configmap game-config -n game-production \
    -p '{"data":{"maintenance_mode":"false"}}'

# 9. ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸
./health-check-all.sh

# 10. ì™„ë£Œ ê³µì§€
send_notification "Maintenance completed successfully"
```

### 4.2 ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜
```sql
-- database-maintenance.sql

-- 1. í…Œì´ë¸” ìµœì í™”
OPTIMIZE TABLE players;
OPTIMIZE TABLE characters;
OPTIMIZE TABLE items;
OPTIMIZE TABLE transactions;

-- 2. ì¸ë±ìŠ¤ ì¬êµ¬ì„±
ALTER TABLE players ENGINE=InnoDB;
ALTER TABLE characters ENGINE=InnoDB;

-- 3. í†µê³„ ì—…ë°ì´íŠ¸
ANALYZE TABLE players;
ANALYZE TABLE characters;

-- 4. íŒŒí‹°ì…˜ ê´€ë¦¬ (ì˜¤ë˜ëœ ë°ì´í„°)
ALTER TABLE game_logs 
DROP PARTITION p_2023_01;

ALTER TABLE game_logs 
ADD PARTITION (
    PARTITION p_2024_02 VALUES LESS THAN (TO_DAYS('2024-03-01'))
);

-- 5. ë¶ˆí•„ìš”í•œ ë°ì´í„° ì •ë¦¬
DELETE FROM player_sessions 
WHERE last_activity < DATE_SUB(NOW(), INTERVAL 30 DAY);

DELETE FROM temporary_data 
WHERE created_at < DATE_SUB(NOW(), INTERVAL 7 DAY);

-- 6. ìºì‹œ ì´ˆê¸°í™”
FLUSH QUERY CACHE;
RESET QUERY CACHE;
```

---

## 5. ë°±ì—… ë° ë³µêµ¬

### 5.1 ë°±ì—… ì ˆì°¨
```bash
#!/bin/bash
# backup-procedure.sh

BACKUP_DIR="/backup/$(date +%Y%m%d)"
S3_BUCKET="s3://game-backups"

echo "=== Starting Backup $(date) ==="

# 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "Backing up database..."
mysqldump -h $DB_HOST -u admin -p$DB_PASS \
    --single-transaction \
    --routines \
    --triggers \
    --events \
    gamedb | gzip > $BACKUP_DIR/gamedb.sql.gz

# 2. Redis ë°±ì—…
echo "Backing up Redis..."
redis-cli -h $REDIS_HOST --rdb $BACKUP_DIR/redis.rdb

# 3. ì„¤ì • íŒŒì¼ ë°±ì—…
echo "Backing up configurations..."
kubectl get configmap -n game-production -o yaml > $BACKUP_DIR/configmaps.yaml
kubectl get secret -n game-production -o yaml > $BACKUP_DIR/secrets.yaml

# 4. íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…
echo "Backing up file system..."
tar -czf $BACKUP_DIR/game-data.tar.gz /data/game-server/

# 5. S3 ì—…ë¡œë“œ
echo "Uploading to S3..."
aws s3 sync $BACKUP_DIR $S3_BUCKET/$(date +%Y%m%d)/ --storage-class GLACIER

# 6. ë°±ì—… ê²€ì¦
echo "Verifying backup..."
./verify-backup.sh $BACKUP_DIR

# 7. ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
find /backup -type d -mtime +30 -exec rm -rf {} \;

echo "=== Backup Complete ==="
```

### 5.2 ë³µêµ¬ ì ˆì°¨
```bash
#!/bin/bash
# restore-procedure.sh

RESTORE_DATE=$1
BACKUP_DIR="/backup/$RESTORE_DATE"

echo "=== Starting Restore from $RESTORE_DATE ==="

# 1. ì„œë¹„ìŠ¤ ì¤‘ë‹¨
kubectl scale deployment/game-server -n game-production --replicas=0

# 2. S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ
aws s3 sync s3://game-backups/$RESTORE_DATE/ $BACKUP_DIR/

# 3. ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
echo "Restoring database..."
gunzip < $BACKUP_DIR/gamedb.sql.gz | mysql -h $DB_HOST -u admin -p$DB_PASS gamedb

# 4. Redis ë³µêµ¬
echo "Restoring Redis..."
redis-cli -h $REDIS_HOST FLUSHALL
redis-cli -h $REDIS_HOST --rdb $BACKUP_DIR/redis.rdb

# 5. ì„¤ì • ë³µêµ¬
echo "Restoring configurations..."
kubectl apply -f $BACKUP_DIR/configmaps.yaml
kubectl apply -f $BACKUP_DIR/secrets.yaml

# 6. íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬
echo "Restoring file system..."
tar -xzf $BACKUP_DIR/game-data.tar.gz -C /

# 7. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
kubectl scale deployment/game-server -n game-production --replicas=5

# 8. ë³µêµ¬ í™•ì¸
./health-check-all.sh

echo "=== Restore Complete ==="
```

---

## 6. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### 6.1 í•µì‹¬ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
```yaml
# monitoring-rules.yaml
groups:
  - name: game_server_alerts
    interval: 30s
    rules:
      # ì„œë²„ ë‹¤ìš´
      - alert: ServerDown
        expr: up{job="game-server"} == 0
        for: 1m
        labels:
          severity: critical
          team: ops
        annotations:
          summary: "Game server {{ $labels.instance }} is down"
          runbook: "https://wiki/runbooks/server-down"
      
      # ë†’ì€ ì—ëŸ¬ìœ¨
      - alert: HighErrorRate
        expr: rate(game_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          team: dev
        annotations:
          summary: "High error rate: {{ $value }} errors/sec"
          runbook: "https://wiki/runbooks/high-error-rate"
      
      # ë©”ëª¨ë¦¬ ë¶€ì¡±
      - alert: LowMemory
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "Low memory on {{ $labels.instance }}"
          runbook: "https://wiki/runbooks/low-memory"
      
      # ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes) < 0.1
        for: 10m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          runbook: "https://wiki/runbooks/low-disk-space"
```

### 6.2 On-Call ë¡œí…Œì´ì…˜
```yaml
oncall_schedule:
  primary:
    - week: 1
      engineer: "alice@company.com"
      backup: "bob@company.com"
    - week: 2
      engineer: "bob@company.com"
      backup: "charlie@company.com"
    - week: 3
      engineer: "charlie@company.com"
      backup: "alice@company.com"
  
  escalation_path:
    - level: 1
      time: "0 minutes"
      contact: "primary_oncall"
    - level: 2
      time: "15 minutes"
      contact: "backup_oncall"
    - level: 3
      time: "30 minutes"
      contact: "team_lead"
    - level: 4
      time: "1 hour"
      contact: "director"
```

---

## 7. ì„±ëŠ¥ íŠœë‹

### 7.1 ì„œë²„ íŒŒë¼ë¯¸í„° íŠœë‹
```bash
#!/bin/bash
# performance-tuning.sh

# ì»¤ë„ íŒŒë¼ë¯¸í„° ìµœì í™”
sysctl -w net.core.somaxconn=65535
sysctl -w net.ipv4.tcp_max_syn_backlog=65535
sysctl -w net.core.netdev_max_backlog=65535
sysctl -w net.ipv4.tcp_fin_timeout=30
sysctl -w net.ipv4.tcp_keepalive_time=300

# íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì¦ê°€
ulimit -n 100000

# CPU ê±°ë²„ë„ˆ ì„¤ì •
cpupower frequency-set -g performance

# NUMA ìµœì í™”
numactl --hardware
numactl --cpunodebind=0 --membind=0 ./game-server

# ë©”ëª¨ë¦¬ ì„¤ì •
echo 0 > /proc/sys/vm/swappiness
echo 3 > /proc/sys/vm/drop_caches
```

### 7.2 ì• í”Œë¦¬ì¼€ì´ì…˜ íŠœë‹
```yaml
# application-tuning.yaml
performance_settings:
  thread_pool:
    core_threads: 16
    max_threads: 64
    queue_size: 10000
  
  connection_pool:
    min_connections: 10
    max_connections: 100
    timeout: 30s
  
  cache:
    size: 4GB
    ttl: 3600s
    eviction_policy: LRU
  
  game_loop:
    tick_rate: 30
    batch_size: 100
    max_latency: 50ms
```

---

## 8. ë¬¸ì„œí™” ë° ì§€ì‹ ê³µìœ 

### 8.1 ì¸ì‹œë˜íŠ¸ ì‚¬í›„ ë¶„ì„ í…œí”Œë¦¿
```markdown
# Incident Post-Mortem: [INCIDENT-ID]

## Summary
- **Date**: 2024-01-15
- **Duration**: 45 minutes
- **Impact**: 30% of users unable to login
- **Root Cause**: Database connection pool exhaustion

## Timeline
- 14:00 - Alert triggered: High error rate
- 14:05 - On-call engineer acknowledged
- 14:10 - Identified database connection issues
- 14:20 - Increased connection pool size
- 14:30 - Service began recovering
- 14:45 - Full service restored

## Root Cause Analysis
The database connection pool was configured with a maximum of 50 connections,
which was insufficient during peak load.

## Lessons Learned
1. Connection pool sizing was based on outdated traffic patterns
2. Monitoring for connection pool metrics was missing
3. No automatic scaling for database connections

## Action Items
- [ ] Increase default connection pool to 200 (Owner: Dev Team)
- [ ] Add connection pool monitoring (Owner: Ops Team)
- [ ] Implement dynamic connection scaling (Owner: Platform Team)
- [ ] Update capacity planning docs (Owner: All)

## Supporting Data
- [Grafana Dashboard](link)
- [Logs](link)
- [Metrics](link)
```

---

## âœ… ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼
- [ ] ì„œë²„ ìƒíƒœ í™•ì¸
- [ ] ì—ëŸ¬ ë¡œê·¸ ê²€í† 
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
- [ ] ë°±ì—… ìƒíƒœ í™•ì¸
- [ ] ì•Œë¦¼ ê²€í† 

### ì£¼ê°„
- [ ] ë³´ì•ˆ ì—…ë°ì´íŠ¸ í™•ì¸
- [ ] ìš©ëŸ‰ ê³„íš ê²€í† 
- [ ] ì¸ì‹œë˜íŠ¸ ë¦¬ë·°
- [ ] ë°±ì—… ë³µêµ¬ í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸

### ì›”ê°„
- [ ] DR í›ˆë ¨
- [ ] ì„±ëŠ¥ ë¦¬í¬íŠ¸
- [ ] ë³´ì•ˆ ê°ì‚¬
- [ ] ë¹„ìš© ìµœì í™”
- [ ] íŒ€ êµìœ¡

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„
â†’ [13_scaling_strategy.md](13_scaling_strategy.md) - ìŠ¤ì¼€ì¼ë§ ì „ëµ