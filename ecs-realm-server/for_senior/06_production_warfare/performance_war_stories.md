# ğŸ”¥ Performance War Stories: ì‹¤ì œ ì„±ëŠ¥ ì¥ì•  ì‚¬ë¡€

## ê°œìš”

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ê²ªì€ **ì„±ëŠ¥ ì¥ì• ì™€ í•´ê²° ê³¼ì •**ì„ ìƒì„¸íˆ ê¸°ë¡í•œ ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

### ğŸ¯ í•™ìŠµ ëª©í‘œ

- **ì‹¤ì œ ì¥ì•  íŒ¨í„´** ì¸ì‹ê³¼ ëŒ€ì‘
- **ê¸´ê¸‰ ìƒí™© ë””ë²„ê¹…** ê¸°ë²•
- **ê·¼ë³¸ ì›ì¸ ë¶„ì„** (RCA) ë°©ë²•ë¡ 
- **ì˜ˆë°©ê³¼ ëª¨ë‹ˆí„°ë§** ì „ëµ

## 1. Case #1: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¡œ ì¸í•œ ì„œë²„ ë©œíŠ¸ë‹¤ìš´

### 1.1 ì¥ì•  ë°œìƒ ìƒí™©

```cpp
// [SEQUENCE: 1] ë¬¸ì œê°€ ëœ ì½”ë“œ
class PlayerManager {
private:
    // ë¬¸ì œì˜ ì‹œì‘: ìŠ¤ë§ˆíŠ¸ í¬ì¸í„° ìˆœí™˜ ì°¸ì¡°
    struct Player {
        uint64_t id;
        std::string name;
        std::shared_ptr<Guild> guild;
        std::vector<std::shared_ptr<Player>> friends;  // ìˆœí™˜ ì°¸ì¡° ìœ„í—˜!
        std::shared_ptr<Inventory> inventory;
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ê°€ ëŒë‹¤ë¡œ ìê¸° ìì‹  ìº¡ì²˜
        std::function<void()> onLevelUp;
    };
    
    std::unordered_map<uint64_t, std::shared_ptr<Player>> players_;
    
public:
    void addPlayer(uint64_t id, const std::string& name) {
        auto player = std::make_shared<Player>();
        player->id = id;
        player->name = name;
        
        // ë¬¸ì œ 1: ëŒë‹¤ê°€ shared_ptr ìº¡ì²˜ë¡œ ìˆœí™˜ ì°¸ì¡° ìƒì„±
        player->onLevelUp = [player]() {  // shared_ptr ìº¡ì²˜!
            std::cout << player->name << " leveled up!\n";
            // í†µê³„ ì—…ë°ì´íŠ¸ ë“±...
        };
        
        players_[id] = player;
    }
    
    void makeFriends(uint64_t player1_id, uint64_t player2_id) {
        auto p1 = players_[player1_id];
        auto p2 = players_[player2_id];
        
        // ë¬¸ì œ 2: ìƒí˜¸ ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ í•´ì œ ë¶ˆê°€
        p1->friends.push_back(p2);
        p2->friends.push_back(p1);
    }
    
    void removePlayer(uint64_t id) {
        players_.erase(id);
        // ì¹œêµ¬ ëª©ë¡ì—ì„œëŠ” ì œê±°í•˜ì§€ ì•ŠìŒ - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜!
    }
};
```

### 1.2 ì¥ì•  ì¦ìƒ ë° íƒ€ì„ë¼ì¸

```
=== Production Incident Timeline ===

Day 1, 14:00 - ìƒˆ ì¹œêµ¬ ì‹œìŠ¤í…œ ë°°í¬
Day 1, 18:00 - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ (8GB/64GB)

Day 2, 10:00 - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‹œì‘ (12GB/64GB)
Day 2, 14:00 - ì²« ì•ŒëŒ: ë©”ëª¨ë¦¬ 20GB ì´ˆê³¼
Day 2, 16:00 - ë©”ëª¨ë¦¬ 32GB, ì‘ë‹µ ì‹œê°„ ì¦ê°€

Day 2, 18:00 - ê¸´ê¸‰ ìƒí™©:
  - ë©”ëª¨ë¦¬: 48GB/64GB
  - í‰ê·  ë ˆì´í„´ì‹œ: 50ms â†’ 800ms
  - ë™ì‹œ ì ‘ì†ì: 5,000ëª…
  - CPU: 95% (GC ìŠ¤ë ˆë“œ)

Day 2, 18:30 - ì²« ë²ˆì§¸ ì„œë²„ OOM Kill
Day 2, 19:00 - ì—°ì‡„ ì¥ì•  ì‹œì‘
```

### 1.3 ê¸´ê¸‰ ëŒ€ì‘ ê³¼ì •

```cpp
// [SEQUENCE: 2] ê¸´ê¸‰ ì§„ë‹¨ ë„êµ¬
class EmergencyDiagnostics {
private:
    // ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ë¤í”„ ë¶„ì„
    void analyzeMemoryUsage() {
        std::cout << "=== Emergency Memory Analysis ===\n";
        
        // /proc/self/status ì½ê¸°
        std::ifstream status("/proc/self/status");
        std::string line;
        while (std::getline(status, line)) {
            if (line.find("VmRSS:") == 0 || 
                line.find("VmSize:") == 0 ||
                line.find("VmPeak:") == 0) {
                std::cout << line << "\n";
            }
        }
        
        // í™ í”„ë¡œíŒŒì¼ë§ (jemalloc)
        if (mallctl) {
            size_t allocated, active, metadata, resident, mapped;
            size_t sz = sizeof(size_t);
            
            mallctl("stats.allocated", &allocated, &sz, NULL, 0);
            mallctl("stats.active", &active, &sz, NULL, 0);
            mallctl("stats.metadata", &metadata, &sz, NULL, 0);
            mallctl("stats.resident", &resident, &sz, NULL, 0);
            mallctl("stats.mapped", &mapped, &sz, NULL, 0);
            
            std::cout << "Heap Allocated: " << allocated / (1024*1024) << " MB\n";
            std::cout << "Heap Active: " << active / (1024*1024) << " MB\n";
            std::cout << "Heap Metadata: " << metadata / (1024*1024) << " MB\n";
        }
    }
    
    // ê°ì²´ ì¹´ìš´íŠ¸ ì¶”ì 
    template<typename T>
    class ObjectCounter {
    private:
        inline static std::atomic<size_t> created_{0};
        inline static std::atomic<size_t> destroyed_{0};
        
    public:
        ObjectCounter() { created_++; }
        ~ObjectCounter() { destroyed_++; }
        
        static void printStats(const std::string& type_name) {
            size_t alive = created_ - destroyed_;
            std::cout << type_name << " - Created: " << created_ 
                     << ", Destroyed: " << destroyed_ 
                     << ", Alive: " << alive << "\n";
        }
    };
    
    // ìˆ˜ì •ëœ Player êµ¬ì¡°ì²´ (ë””ë²„ê¹…ìš©)
    struct DiagnosticPlayer : ObjectCounter<DiagnosticPlayer> {
        uint64_t id;
        std::weak_ptr<Guild> guild;  // weak_ptrë¡œ ë³€ê²½
        std::vector<std::weak_ptr<DiagnosticPlayer>> friends;  // weak_ptrë¡œ ë³€ê²½
        
        ~DiagnosticPlayer() {
            // ì†Œë©¸ìì—ì„œ ë¡œê¹…
            std::cout << "Player " << id << " destroyed\n";
        }
    };
    
public:
    // ê¸´ê¸‰ íŒ¨ì¹˜ ë°°í¬
    void deployEmergencyFix() {
        std::cout << "Deploying emergency fix...\n";
        
        // 1. ê¸°ì¡´ ìˆœí™˜ ì°¸ì¡° ëŠê¸°
        breakCircularReferences();
        
        // 2. ê°•ì œ GC íŠ¸ë¦¬ê±°
        forceGarbageCollection();
        
        // 3. ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
        setMemoryLimits();
    }
    
    void breakCircularReferences() {
        // ëª¨ë“  í”Œë ˆì´ì–´ì˜ ì¹œêµ¬ ëª©ë¡ì„ weak_ptrë¡œ ë³€í™˜
        for (auto& [id, player] : players_) {
            // ëŒë‹¤ ìº¡ì²˜ë¥¼ weak_ptrë¡œ ë³€ê²½
            std::weak_ptr<Player> weak_player = player;
            player->onLevelUp = [weak_player]() {
                if (auto p = weak_player.lock()) {
                    std::cout << p->name << " leveled up!\n";
                }
            };
            
            // ì¹œêµ¬ ëª©ë¡ ì •ë¦¬
            player->friends.clear();
        }
    }
    
    void forceGarbageCollection() {
        // C++ëŠ” GCê°€ ì—†ì§€ë§Œ, ìŠ¤ë§ˆíŠ¸ í¬ì¸í„° ì •ë¦¬ ê°•ì œ
        std::cout << "Forcing cleanup...\n";
        
        // ëª¨ë“  expired weak_ptr ì œê±°
        for (auto& [id, player] : players_) {
            player->friends.erase(
                std::remove_if(player->friends.begin(), player->friends.end(),
                    [](const std::weak_ptr<Player>& wp) { return wp.expired(); }),
                player->friends.end()
            );
        }
        
        // ë©”ëª¨ë¦¬ ì••ì¶• íŒíŠ¸
        malloc_trim(0);
    }
};
```

### 1.4 ê·¼ë³¸ ì›ì¸ ë¶„ì„ (RCA)

```cpp
// [SEQUENCE: 3] ì‚¬í›„ ë¶„ì„ ë„êµ¬
class PostMortemAnalyzer {
private:
    // ë©”ëª¨ë¦¬ í• ë‹¹ ì¶”ì 
    class AllocationTracker {
    private:
        struct AllocationInfo {
            void* ptr;
            size_t size;
            std::string stack_trace;
            uint64_t timestamp;
        };
        
        std::unordered_map<void*, AllocationInfo> allocations_;
        std::mutex tracker_mutex_;
        std::atomic<size_t> total_allocated_{0};
        
        std::string captureStackTrace() {
            void* buffer[20];
            int nptrs = backtrace(buffer, 20);
            char** strings = backtrace_symbols(buffer, nptrs);
            
            std::stringstream ss;
            for (int i = 0; i < nptrs; ++i) {
                ss << strings[i] << "\n";
            }
            
            free(strings);
            return ss.str();
        }
        
    public:
        void trackAllocation(void* ptr, size_t size) {
            std::lock_guard<std::mutex> lock(tracker_mutex_);
            
            AllocationInfo info;
            info.ptr = ptr;
            info.size = size;
            info.stack_trace = captureStackTrace();
            info.timestamp = getCurrentTimestamp();
            
            allocations_[ptr] = info;
            total_allocated_ += size;
        }
        
        void trackDeallocation(void* ptr) {
            std::lock_guard<std::mutex> lock(tracker_mutex_);
            
            auto it = allocations_.find(ptr);
            if (it != allocations_.end()) {
                total_allocated_ -= it->second.size;
                allocations_.erase(it);
            }
        }
        
        void generateLeakReport() {
            std::cout << "=== Memory Leak Report ===\n";
            std::cout << "Total leaked: " << total_allocated_ / (1024*1024) << " MB\n";
            
            // í¬ê¸°ë³„ë¡œ ì •ë ¬
            std::vector<AllocationInfo> leaks;
            for (const auto& [ptr, info] : allocations_) {
                leaks.push_back(info);
            }
            
            std::sort(leaks.begin(), leaks.end(),
                [](const auto& a, const auto& b) { return a.size > b.size; });
            
            // ìƒìœ„ 10ê°œ ëˆ„ìˆ˜ ì¶œë ¥
            std::cout << "\nTop 10 Leaks:\n";
            for (size_t i = 0; i < std::min(size_t(10), leaks.size()); ++i) {
                std::cout << i+1 << ". Size: " << leaks[i].size << " bytes\n";
                std::cout << "   Stack trace:\n" << leaks[i].stack_trace << "\n";
            }
        }
    };
    
    // ê·¼ë³¸ ì›ì¸ ì°¾ê¸°
    void findRootCause() {
        std::cout << "\n=== Root Cause Analysis ===\n";
        
        // 1. ìˆœí™˜ ì°¸ì¡° íŒ¨í„´ ì°¾ê¸°
        detectCircularReferences();
        
        // 2. ë©”ëª¨ë¦¬ í• ë‹¹ íŒ¨í„´ ë¶„ì„
        analyzeAllocationPatterns();
        
        // 3. íƒ€ì„ë¼ì¸ ì¬êµ¬ì„±
        reconstructTimeline();
    }
    
    void detectCircularReferences() {
        // shared_ptr ì°¸ì¡° ì¹´ìš´íŠ¸ ë¶„ì„
        std::cout << "Analyzing reference counts...\n";
        
        size_t circular_refs = 0;
        for (const auto& [id, player] : players_) {
            if (player.use_count() > 1) {
                // DFSë¡œ ìˆœí™˜ ì°¸ì¡° íƒì§€
                std::unordered_set<uint64_t> visited;
                if (hasCircularReference(player, visited)) {
                    circular_refs++;
                }
            }
        }
        
        std::cout << "Found " << circular_refs << " circular references\n";
    }
    
public:
    // ìµœì¢… í•´ê²°ì±…
    void implementPermanentFix() {
        std::cout << "\n=== Permanent Solution ===\n";
        
        // 1. ì•„í‚¤í…ì²˜ ê°œì„ 
        std::cout << "1. Replacing shared_ptr with weak_ptr for cross-references\n";
        std::cout << "2. Implementing proper cleanup in destructors\n";
        std::cout << "3. Adding memory leak detection in CI/CD\n";
        
        // 2. ëª¨ë‹ˆí„°ë§ ê°•í™”
        std::cout << "4. Real-time memory tracking dashboard\n";
        std::cout << "5. Automated leak detection alerts\n";
        std::cout << "6. Memory growth trend analysis\n";
    }
};
```

## 2. Case #2: ìºì‹œ ìŠ¤íƒ¬í”¼ë“œë¡œ ì¸í•œ DB ë‹¤ìš´

### 2.1 ë¬¸ì œ ìƒí™©

```cpp
// [SEQUENCE: 4] ë¬¸ì œê°€ ëœ ìºì‹œ ì½”ë“œ
class GameCache {
private:
    struct CacheEntry {
        std::string data;
        std::chrono::steady_clock::time_point expiry;
    };
    
    std::unordered_map<std::string, CacheEntry> cache_;
    std::shared_mutex cache_mutex_;
    
    // ë¬¸ì œ: ë™ì‹œì— ë§ì€ ìš”ì²­ì´ ìºì‹œ ë¯¸ìŠ¤ ì‹œ DB í­ì£¼
    std::string getData(const std::string& key) {
        {
            std::shared_lock<std::shared_mutex> lock(cache_mutex_);
            auto it = cache_.find(key);
            if (it != cache_.end() && it->second.expiry > std::chrono::steady_clock::now()) {
                return it->second.data;  // ìºì‹œ íˆíŠ¸
            }
        }
        
        // ë¬¸ì œ ì§€ì : ì—¬ëŸ¬ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— ì—¬ê¸° ë„ë‹¬!
        std::string data = fetchFromDatabase(key);  // DB ì¿¼ë¦¬ í­ì£¼
        
        {
            std::unique_lock<std::shared_mutex> lock(cache_mutex_);
            cache_[key] = {data, std::chrono::steady_clock::now() + std::chrono::seconds(60)};
        }
        
        return data;
    }
};
```

### 2.2 ì¥ì•  ë°œìƒ ê³¼ì •

```
=== Cache Stampede Timeline ===

17:00:00 - ì¸ê¸° ì•„ì´í…œ "ì „ì„¤ì˜ ê²€" ì´ë²¤íŠ¸ ì‹œì‘
17:00:01 - ìºì‹œ TTL ë§Œë£Œ (60ì´ˆ ì£¼ê¸°)
17:00:01.001 - 1,000ê°œ ë™ì‹œ ìš”ì²­ ë°œìƒ
17:00:01.002 - ëª¨ë“  ìš”ì²­ì´ ìºì‹œ ë¯¸ìŠ¤
17:00:01.003 - 1,000ê°œ DB ì¿¼ë¦¬ ë™ì‹œ ì‹¤í–‰
17:00:01.500 - DB ì»¤ë„¥ì…˜ í’€ ê³ ê°ˆ (max: 100)
17:00:02.000 - DB ì‘ë‹µ ì‹œê°„ 10ms â†’ 5,000ms
17:00:05.000 - ì• í”Œë¦¬ì¼€ì´ì…˜ íƒ€ì„ì•„ì›ƒ ì‹œì‘
17:00:10.000 - ì—°ì‡„ ì¥ì• : ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë„ ì˜í–¥
17:00:30.000 - DB ì„œë²„ CPU 100%, ë©”ëª¨ë¦¬ ë¶€ì¡±
17:01:00.000 - DB ì‘ë‹µ ë¶ˆê°€, ì „ì²´ ì„œë¹„ìŠ¤ ë‹¤ìš´
```

### 2.3 í•´ê²° ê³¼ì •

```cpp
// [SEQUENCE: 5] ìºì‹œ ìŠ¤íƒ¬í”¼ë“œ í•´ê²°ì±…
class ImprovedGameCache {
private:
    struct CacheEntry {
        std::string data;
        std::chrono::steady_clock::time_point expiry;
        std::chrono::steady_clock::time_point stale_time;  // ì†Œí”„íŠ¸ ë§Œë£Œ
        std::atomic<bool> refreshing{false};  // ê°±ì‹  ì¤‘ í”Œë˜ê·¸
    };
    
    std::unordered_map<std::string, CacheEntry> cache_;
    std::shared_mutex cache_mutex_;
    
    // í•´ê²°ì±… 1: í™•ë¥ ì  ì¡°ê¸° ë§Œë£Œ (Probabilistic Early Expiration)
    bool shouldRefreshEarly(const CacheEntry& entry) {
        auto now = std::chrono::steady_clock::now();
        auto ttl = entry.expiry - entry.stale_time;
        auto elapsed = now - entry.stale_time;
        
        // XFetch ì•Œê³ ë¦¬ì¦˜
        double probability = 1.0 - std::exp(-elapsed.count() / static_cast<double>(ttl.count()));
        
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<> dis(0.0, 1.0);
        
        return dis(gen) < probability;
    }
    
    // í•´ê²°ì±… 2: ë½ ê¸°ë°˜ ë‹¨ì¼ ê°±ì‹ 
    std::string getDataWithSingleFlight(const std::string& key) {
        while (true) {
            {
                std::shared_lock<std::shared_mutex> lock(cache_mutex_);
                auto it = cache_.find(key);
                
                if (it != cache_.end()) {
                    auto& entry = it->second;
                    
                    // ì•„ì§ ìœ íš¨í•œ ë°ì´í„°
                    if (std::chrono::steady_clock::now() < entry.expiry) {
                        // ì¡°ê¸° ê°±ì‹  ì²´í¬
                        if (shouldRefreshEarly(entry)) {
                            bool expected = false;
                            if (entry.refreshing.compare_exchange_strong(expected, true)) {
                                // ë°±ê·¸ë¼ìš´ë“œ ê°±ì‹  ì‹œì‘
                                std::thread([this, key]() {
                                    refreshInBackground(key);
                                }).detach();
                            }
                        }
                        return entry.data;
                    }
                    
                    // ë§Œë£Œëì§€ë§Œ ê°±ì‹  ì¤‘
                    if (entry.refreshing.load()) {
                        // ìŠ¤í…Œì¼ ë°ì´í„° ë°˜í™˜ (ê°€ìš©ì„± ìš°ì„ )
                        return entry.data;
                    }
                }
            }
            
            // ë‹¨ì¼ ìŠ¤ë ˆë“œë§Œ ê°±ì‹ 
            static std::unordered_map<std::string, std::mutex> key_mutexes;
            static std::mutex map_mutex;
            
            std::unique_lock<std::mutex> map_lock(map_mutex);
            auto& key_mutex = key_mutexes[key];
            map_lock.unlock();
            
            std::unique_lock<std::mutex> key_lock(key_mutex, std::try_to_lock);
            if (key_lock.owns_lock()) {
                // ê°±ì‹  ìˆ˜í–‰
                return refreshAndGet(key);
            } else {
                // ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ê°±ì‹  ì¤‘, ì ì‹œ ëŒ€ê¸°
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
            }
        }
    }
    
    // í•´ê²°ì±… 3: ë¶„ì‚° ë½ (Redis ê¸°ë°˜)
    class DistributedLock {
    private:
        std::string redis_key_;
        std::string lock_value_;
        int ttl_seconds_;
        
    public:
        bool acquire(const std::string& key, int ttl = 5) {
            redis_key_ = "lock:" + key;
            lock_value_ = generateUUID();
            ttl_seconds_ = ttl;
            
            // SET key value NX EX ttl
            return redisSetNX(redis_key_, lock_value_, ttl_seconds_);
        }
        
        void release() {
            // Lua ìŠ¤í¬ë¦½íŠ¸ë¡œ ì›ìì  í•´ì œ
            const char* lua_script = 
                "if redis.call('get', KEYS[1]) == ARGV[1] then "
                "    return redis.call('del', KEYS[1]) "
                "else "
                "    return 0 "
                "end";
            
            redisEval(lua_script, redis_key_, lock_value_);
        }
    };
    
    // í•´ê²°ì±… 4: ì ì‘í˜• TTL
    class AdaptiveTTL {
    private:
        struct AccessStats {
            std::atomic<uint64_t> hit_count{0};
            std::atomic<uint64_t> miss_count{0};
            std::chrono::steady_clock::time_point last_access;
        };
        
        std::unordered_map<std::string, AccessStats> stats_;
        
    public:
        std::chrono::seconds calculateTTL(const std::string& key) {
            auto& stat = stats_[key];
            
            double hit_rate = static_cast<double>(stat.hit_count) / 
                            (stat.hit_count + stat.miss_count + 1);
            
            // íˆíŠ¸ìœ¨ì´ ë†’ìœ¼ë©´ TTL ì¦ê°€
            int base_ttl = 60;
            int adaptive_ttl = base_ttl * (1.0 + hit_rate);
            
            // ì•¡ì„¸ìŠ¤ ë¹ˆë„ ê³ ë ¤
            auto now = std::chrono::steady_clock::now();
            auto time_since_last = now - stat.last_access;
            
            if (time_since_last < std::chrono::seconds(10)) {
                adaptive_ttl *= 2;  // ìì£¼ ì•¡ì„¸ìŠ¤ë˜ë©´ TTL 2ë°°
            }
            
            return std::chrono::seconds(std::min(adaptive_ttl, 3600));
        }
    };
    
private:
    void refreshInBackground(const std::string& key) {
        try {
            std::string new_data = fetchFromDatabase(key);
            
            std::unique_lock<std::shared_mutex> lock(cache_mutex_);
            auto& entry = cache_[key];
            entry.data = new_data;
            entry.stale_time = std::chrono::steady_clock::now();
            entry.expiry = entry.stale_time + calculateAdaptiveTTL(key);
            entry.refreshing = false;
        } catch (...) {
            // ì‹¤íŒ¨ ì‹œì—ë„ í”Œë˜ê·¸ í•´ì œ
            cache_[key].refreshing = false;
        }
    }
};
```

## 3. Case #3: ë½ ê²½í•©ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜

### 3.1 ë¬¸ì œ ì½”ë“œ

```cpp
// [SEQUENCE: 6] ê³¼ë„í•œ ë½ ê²½í•© ë¬¸ì œ
class InventorySystem {
private:
    struct Inventory {
        std::unordered_map<uint32_t, uint32_t> items;  // item_id -> count
        mutable std::mutex mutex;  // ì¸ë²¤í† ë¦¬ë³„ ë®¤í…ìŠ¤
    };
    
    std::unordered_map<uint64_t, Inventory> player_inventories_;
    mutable std::mutex global_mutex_;  // ë¬¸ì œ: ì „ì—­ ë®¤í…ìŠ¤!
    
    // ë¬¸ì œ: ëª¨ë“  ì‘ì—…ì´ ì „ì—­ ë½ í•„ìš”
    bool transferItem(uint64_t from_player, uint64_t to_player, 
                     uint32_t item_id, uint32_t count) {
        std::lock_guard<std::mutex> global_lock(global_mutex_);
        
        auto from_it = player_inventories_.find(from_player);
        auto to_it = player_inventories_.find(to_player);
        
        if (from_it == player_inventories_.end() || 
            to_it == player_inventories_.end()) {
            return false;
        }
        
        // ì¤‘ì²© ë½ - ë°ë“œë½ ìœ„í—˜!
        std::lock_guard<std::mutex> from_lock(from_it->second.mutex);
        std::lock_guard<std::mutex> to_lock(to_it->second.mutex);
        
        // ì•„ì´í…œ ì „ì†¡ ë¡œì§...
        return true;
    }
};
```

### 3.2 ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê²°ê³¼

```
=== Lock Contention Analysis ===

Total CPU Time: 100%
- User Space: 15%
- Kernel Space: 85% (ëŒ€ë¶€ë¶„ futex_wait)

Thread States:
- Running: 8 (8 cores)
- Blocked on Mutex: 792
- Total Threads: 800

Lock Statistics (from perf):
- global_mutex_:
  - Contention Rate: 98.5%
  - Average Wait Time: 125ms
  - Max Wait Time: 2,450ms

Hot Path Analysis:
1. transferItem() - 45% of lock time
2. addItem() - 30% of lock time
3. removeItem() - 20% of lock time
4. Others - 5%

Performance Impact:
- Throughput: 50K ops/sec â†’ 2K ops/sec
- Latency P99: 5ms â†’ 850ms
- CPU Efficiency: 5% (95% waiting)
```

### 3.3 ë‹¨ê³„ë³„ í•´ê²° ê³¼ì •

```cpp
// [SEQUENCE: 7] ë½ ê²½í•© í•´ê²° ë°©ë²•ë“¤
class OptimizedInventorySystem {
private:
    // í•´ê²°ì±… 1: ë½ ì„¸ë¶„í™” (Fine-grained Locking)
    struct ShardedInventories {
        static constexpr size_t SHARD_COUNT = 64;
        
        struct Shard {
            std::unordered_map<uint64_t, Inventory> inventories;
            mutable std::shared_mutex mutex;
        };
        
        std::array<Shard, SHARD_COUNT> shards;
        
        Shard& getShard(uint64_t player_id) {
            return shards[player_id % SHARD_COUNT];
        }
    };
    
    // í•´ê²°ì±… 2: ë½í”„ë¦¬ ì—…ë°ì´íŠ¸ í
    class LockFreeUpdateQueue {
    private:
        struct UpdateCommand {
            enum Type { ADD, REMOVE, TRANSFER };
            Type type;
            uint64_t player_id;
            uint64_t target_id;  // for transfer
            uint32_t item_id;
            uint32_t count;
            std::promise<bool> result;
        };
        
        // MPSC ë½í”„ë¦¬ í
        moodycamel::ConcurrentQueue<std::unique_ptr<UpdateCommand>> queue_;
        std::thread worker_thread_;
        std::atomic<bool> running_{true};
        
        void workerLoop() {
            std::unique_ptr<UpdateCommand> cmd;
            
            while (running_) {
                if (queue_.try_dequeue(cmd)) {
                    bool result = processCommand(*cmd);
                    cmd->result.set_value(result);
                } else {
                    std::this_thread::sleep_for(std::chrono::microseconds(10));
                }
            }
        }
        
    public:
        std::future<bool> submitUpdate(UpdateCommand cmd) {
            auto future = cmd.result.get_future();
            queue_.enqueue(std::make_unique<UpdateCommand>(std::move(cmd)));
            return future;
        }
    };
    
    // í•´ê²°ì±… 3: ì½ê¸° ì“°ê¸° ë½ ë¶„ë¦¬
    class RWLockInventory {
    private:
        struct VersionedInventory {
            std::atomic<uint64_t> version{0};
            std::unordered_map<uint32_t, uint32_t> items;
        };
        
        std::unordered_map<uint64_t, std::unique_ptr<VersionedInventory>> inventories_;
        mutable std::shared_mutex rw_mutex_;
        
    public:
        // ì½ê¸°ëŠ” ë½ ì—†ì´
        std::optional<uint32_t> getItemCount(uint64_t player_id, uint32_t item_id) const {
            std::shared_lock<std::shared_mutex> lock(rw_mutex_);
            
            auto it = inventories_.find(player_id);
            if (it == inventories_.end()) return std::nullopt;
            
            uint64_t version_before = it->second->version.load();
            
            auto item_it = it->second->items.find(item_id);
            uint32_t count = (item_it != it->second->items.end()) ? item_it->second : 0;
            
            uint64_t version_after = it->second->version.load();
            
            // ì½ëŠ” ë™ì•ˆ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if (version_before != version_after) {
                return getItemCount(player_id, item_id);  // ì¬ì‹œë„
            }
            
            return count;
        }
    };
    
    // í•´ê²°ì±… 4: ìŠ¤ë ˆë“œ ë¡œì»¬ ìºì‹±
    class ThreadLocalCache {
    private:
        struct CacheEntry {
            uint64_t player_id;
            std::unordered_map<uint32_t, uint32_t> items;
            std::chrono::steady_clock::time_point last_update;
        };
        
        static thread_local std::unordered_map<uint64_t, CacheEntry> tl_cache_;
        
    public:
        std::optional<uint32_t> getCached(uint64_t player_id, uint32_t item_id) {
            auto it = tl_cache_.find(player_id);
            if (it == tl_cache_.end()) return std::nullopt;
            
            auto now = std::chrono::steady_clock::now();
            if (now - it->second.last_update > std::chrono::milliseconds(100)) {
                tl_cache_.erase(it);  // ìºì‹œ ë§Œë£Œ
                return std::nullopt;
            }
            
            auto item_it = it->second.items.find(item_id);
            return (item_it != it->second.items.end()) ? 
                   std::optional<uint32_t>(item_it->second) : std::nullopt;
        }
    };
    
    // í•´ê²°ì±… 5: ë°°ì¹˜ ì²˜ë¦¬
    class BatchProcessor {
    private:
        struct BatchUpdate {
            std::vector<UpdateCommand> commands;
            std::chrono::steady_clock::time_point deadline;
        };
        
        std::queue<BatchUpdate> pending_batches_;
        std::mutex batch_mutex_;
        
    public:
        void processBatch() {
            std::unique_lock<std::mutex> lock(batch_mutex_);
            if (pending_batches_.empty()) return;
            
            BatchUpdate batch = std::move(pending_batches_.front());
            pending_batches_.pop();
            lock.unlock();
            
            // í”Œë ˆì´ì–´ë³„ë¡œ ì •ë ¬í•˜ì—¬ ë½ ìˆœì„œ ë³´ì¥
            std::sort(batch.commands.begin(), batch.commands.end(),
                [](const auto& a, const auto& b) { return a.player_id < b.player_id; });
            
            // ë°°ì¹˜ ì‹¤í–‰
            for (const auto& cmd : batch.commands) {
                executeCommand(cmd);
            }
        }
    };
    
    // ìµœì¢… í†µí•© ì†”ë£¨ì…˜
    void implementFinalSolution() {
        std::cout << "=== Lock Contention Solution ===\n";
        std::cout << "1. Sharding: 64 shards reduce contention by 64x\n";
        std::cout << "2. Lock-free queues: Async updates\n";
        std::cout << "3. RW locks: 90% reads don't block each other\n";
        std::cout << "4. Thread-local caching: 95% cache hit rate\n";
        std::cout << "5. Batch processing: 10x throughput improvement\n";
        
        // ê²°ê³¼
        std::cout << "\nPerformance After Fix:\n";
        std::cout << "- Throughput: 2K â†’ 480K ops/sec\n";
        std::cout << "- Latency P99: 850ms â†’ 8ms\n";
        std::cout << "- CPU Efficiency: 5% â†’ 87%\n";
    }
};
```

## 4. ì¥ì•  ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 4.1 ì¦‰ì‹œ ëŒ€ì‘ í”„ë¡œí† ì½œ

```cpp
// [SEQUENCE: 8] ì¥ì•  ëŒ€ì‘ ìë™í™” ë„êµ¬
class IncidentResponseSystem {
private:
    enum class Severity { LOW, MEDIUM, HIGH, CRITICAL };
    
    struct IncidentMetrics {
        double cpu_usage;
        double memory_usage;
        double error_rate;
        double response_time_p99;
        uint32_t active_connections;
    };
    
    // ìë™ ì§„ë‹¨ ë° ëŒ€ì‘
    class AutoResponder {
    private:
        std::vector<std::function<bool(const IncidentMetrics&)>> detectors_;
        std::vector<std::function<void()>> responses_;
        
    public:
        void initialize() {
            // CPU ê³¼ë¶€í•˜ ê°ì§€ ë° ëŒ€ì‘
            detectors_.push_back([](const IncidentMetrics& m) {
                return m.cpu_usage > 90.0;
            });
            responses_.push_back([]() {
                std::cout << "[AUTO] CPU throttling detected, enabling rate limiting\n";
                enableRateLimiting(0.8);  // 20% íŠ¸ë˜í”½ ê°ì†Œ
            });
            
            // ë©”ëª¨ë¦¬ ë¶€ì¡± ê°ì§€ ë° ëŒ€ì‘
            detectors_.push_back([](const IncidentMetrics& m) {
                return m.memory_usage > 85.0;
            });
            responses_.push_back([]() {
                std::cout << "[AUTO] Memory pressure detected, clearing caches\n";
                clearNonEssentialCaches();
                forceGarbageCollection();
            });
            
            // ì‘ë‹µ ì‹œê°„ ì¦ê°€ ê°ì§€
            detectors_.push_back([](const IncidentMetrics& m) {
                return m.response_time_p99 > 1000.0;  // 1ì´ˆ
            });
            responses_.push_back([]() {
                std::cout << "[AUTO] High latency detected, enabling circuit breaker\n";
                enableCircuitBreaker();
            });
        }
        
        void checkAndRespond(const IncidentMetrics& metrics) {
            for (size_t i = 0; i < detectors_.size(); ++i) {
                if (detectors_[i](metrics)) {
                    responses_[i]();
                }
            }
        }
    };
    
    // ì‹¤ì‹œê°„ ì§„ë‹¨ ë„êµ¬
    class LiveDiagnostics {
    public:
        void captureSystemState() {
            std::cout << "\n=== EMERGENCY DIAGNOSTICS ===\n";
            std::cout << "Timestamp: " << getCurrentTimestamp() << "\n\n";
            
            // 1. í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
            captureProcessState();
            
            // 2. ìŠ¤ë ˆë“œ ë¤í”„
            captureThreadDump();
            
            // 3. ë©”ëª¨ë¦¬ ìƒíƒœ
            captureMemoryState();
            
            // 4. ë„¤íŠ¸ì›Œí¬ ìƒíƒœ
            captureNetworkState();
            
            // 5. ìµœê·¼ ì—ëŸ¬ ë¡œê·¸
            captureRecentErrors();
        }
        
    private:
        void captureThreadDump() {
            std::cout << "=== Thread Dump ===\n";
            
            // ëª¨ë“  ìŠ¤ë ˆë“œ ì •ë³´ ìˆ˜ì§‘
            for (const auto& thread_id : getAllThreadIds()) {
                std::cout << "Thread " << thread_id << ":\n";
                
                // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤
                void* buffer[50];
                int nptrs = backtrace(buffer, 50);
                backtrace_symbols_fd(buffer, nptrs, STDOUT_FILENO);
                
                std::cout << "\n";
            }
        }
        
        void captureMemoryState() {
            std::cout << "=== Memory State ===\n";
            
            // í™ ì •ë³´
            malloc_info(0, stdout);
            
            // ê°€ìƒ ë©”ëª¨ë¦¬ ì •ë³´
            std::ifstream vmstat("/proc/self/status");
            std::string line;
            while (std::getline(vmstat, line)) {
                if (line.find("Vm") == 0) {
                    std::cout << line << "\n";
                }
            }
        }
    };
    
public:
    // ì¥ì•  ëŒ€ì‘ í”Œë ˆì´ë¶
    void executePlaybook(Severity severity) {
        switch (severity) {
            case Severity::CRITICAL:
                std::cout << "\n=== CRITICAL INCIDENT RESPONSE ===\n";
                // 1. ì¦‰ì‹œ íŠ¸ë˜í”½ ì°¨ë‹¨
                blockIncomingTraffic();
                // 2. ì‹œìŠ¤í…œ ìƒíƒœ ë¤í”„
                createFullSystemDump();
                // 3. ë¡¤ë°± ì¤€ë¹„
                prepareRollback();
                // 4. ì•Œë¦¼ ë°œì†¡
                notifyOncallTeam();
                break;
                
            case Severity::HIGH:
                // ë¶€ë¶„ ê²©ë¦¬ ë° ë³µêµ¬ ì‹œë„
                isolateProblematicComponents();
                attemptAutoRecovery();
                break;
                
            case Severity::MEDIUM:
                // ëª¨ë‹ˆí„°ë§ ê°•í™” ë° ì˜ˆë°© ì¡°ì¹˜
                increaseMonitoringGranularity();
                enableDefensiveMode();
                break;
                
            case Severity::LOW:
                // ë¡œê¹… ë° ì¶”ì 
                enableDetailedLogging();
                break;
        }
    }
    
private:
    static void enableRateLimiting(double factor) {
        // ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… êµ¬í˜„
    }
    
    static void clearNonEssentialCaches() {
        // ìºì‹œ ì •ë¦¬ êµ¬í˜„
    }
    
    static void forceGarbageCollection() {
        malloc_trim(0);
    }
    
    static void enableCircuitBreaker() {
        // ì„œí‚· ë¸Œë ˆì´ì»¤ êµ¬í˜„
    }
};
```

## 5. êµí›ˆê³¼ ì˜ˆë°©ì±…

### 5.1 ì‚¬í›„ ê°œì„  ì‚¬í•­

```cpp
// [SEQUENCE: 9] ì¥ì•  ì˜ˆë°© ì‹œìŠ¤í…œ
class IncidentPreventionSystem {
private:
    // ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§
    class ChaosMonkey {
    public:
        void runRandomFailures() {
            std::random_device rd;
            std::mt19937 gen(rd());
            std::uniform_int_distribution<> dis(1, 100);
            
            int failure_type = dis(gen);
            
            if (failure_type <= 5) {
                // 5% í™•ë¥ ë¡œ ë©”ëª¨ë¦¬ ì••ë°•
                simulateMemoryPressure();
            } else if (failure_type <= 10) {
                // 5% í™•ë¥ ë¡œ CPU ìŠ¤íŒŒì´í¬
                simulateCPUSpike();
            } else if (failure_type <= 15) {
                // 5% í™•ë¥ ë¡œ ë„¤íŠ¸ì›Œí¬ ì§€ì—°
                simulateNetworkLatency();
            }
        }
        
    private:
        void simulateMemoryPressure() {
            std::cout << "[CHAOS] Simulating memory pressure\n";
            std::vector<char> dummy(100 * 1024 * 1024);  // 100MB í• ë‹¹
            std::this_thread::sleep_for(std::chrono::seconds(10));
        }
    };
    
    // ì„±ëŠ¥ íšŒê·€ ê°ì§€
    class PerformanceRegression {
    private:
        struct Baseline {
            double avg_latency;
            double p99_latency;
            double throughput;
            double cpu_usage;
            double memory_usage;
        };
        
        Baseline production_baseline_;
        
    public:
        bool detectRegression(const Baseline& current) {
            // 10% ì´ìƒ ì„±ëŠ¥ ì €í•˜ ê°ì§€
            if (current.avg_latency > production_baseline_.avg_latency * 1.1 ||
                current.p99_latency > production_baseline_.p99_latency * 1.1 ||
                current.throughput < production_baseline_.throughput * 0.9) {
                
                std::cout << "[ALERT] Performance regression detected!\n";
                std::cout << "Avg latency: " << production_baseline_.avg_latency 
                         << " â†’ " << current.avg_latency << "\n";
                return true;
            }
            return false;
        }
    };
    
    // ìë™í™”ëœ ë¶€í•˜ í…ŒìŠ¤íŠ¸
    class LoadTestAutomation {
    public:
        void runLoadTest() {
            std::cout << "=== Automated Load Test ===\n";
            
            // ì ì§„ì  ë¶€í•˜ ì¦ê°€
            for (int concurrent = 100; concurrent <= 10000; concurrent *= 2) {
                std::cout << "Testing with " << concurrent << " concurrent users\n";
                
                auto results = simulateLoad(concurrent, 60);  // 60ì´ˆ í…ŒìŠ¤íŠ¸
                
                if (results.error_rate > 0.01) {  // 1% ì—ëŸ¬ìœ¨ ì´ˆê³¼
                    std::cout << "[FAIL] Error rate too high: " 
                             << results.error_rate * 100 << "%\n";
                    break;
                }
                
                if (results.p99_latency > 1000) {  // 1ì´ˆ ì´ˆê³¼
                    std::cout << "[FAIL] P99 latency too high: " 
                             << results.p99_latency << "ms\n";
                    break;
                }
            }
        }
    };
    
public:
    // í†µí•© ì˜ˆë°© ì‹œìŠ¤í…œ
    void setupPreventionMeasures() {
        std::cout << "=== Setting Up Prevention Measures ===\n";
        
        // 1. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
        std::cout << "âœ“ Memory leak detection in CI/CD\n";
        
        // 2. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ìë™í™”
        std::cout << "âœ“ Automated performance profiling\n";
        
        // 3. ì¹´ë‚˜ë¦¬ ë°°í¬
        std::cout << "âœ“ Canary deployment with auto-rollback\n";
        
        // 4. ì‹¤ì‹œê°„ ì´ìƒ ê°ì§€
        std::cout << "âœ“ Real-time anomaly detection\n";
        
        // 5. ìë™ ìŠ¤ì¼€ì¼ë§
        std::cout << "âœ“ Auto-scaling based on metrics\n";
        
        // 6. ì¥ì•  ì£¼ì… í…ŒìŠ¤íŠ¸
        std::cout << "âœ“ Chaos engineering in staging\n";
    }
};
```

## í•µì‹¬ êµí›ˆ

### 1. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì‚¬ë¡€
- **ì›ì¸**: shared_ptr ìˆœí™˜ ì°¸ì¡°
- **ì¦ìƒ**: ì ì§„ì  ë©”ëª¨ë¦¬ ì¦ê°€, GC ì••ë°•
- **í•´ê²°**: weak_ptr ì‚¬ìš©, RAII íŒ¨í„´
- **ì˜ˆë°©**: ìë™ ëˆ„ìˆ˜ ê°ì§€, ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§

### 2. ìºì‹œ ìŠ¤íƒ¬í”¼ë“œ ì‚¬ë¡€  
- **ì›ì¸**: ë™ì‹œ ìºì‹œ ë¯¸ìŠ¤
- **ì¦ìƒ**: DB ê³¼ë¶€í•˜, ì—°ì‡„ ì¥ì• 
- **í•´ê²°**: í™•ë¥ ì  ì¡°ê¸° ê°±ì‹ , ë¶„ì‚° ë½
- **ì˜ˆë°©**: ì ì‘í˜• TTL, ë¶€í•˜ í…ŒìŠ¤íŠ¸

### 3. ë½ ê²½í•© ì‚¬ë¡€
- **ì›ì¸**: êµµì€ ì…ì ë½
- **ì¦ìƒ**: CPU ëŒ€ê¸°, ì²˜ë¦¬ëŸ‰ ê¸‰ê°
- **í•´ê²°**: ë½ ì„¸ë¶„í™”, ë½í”„ë¦¬ êµ¬ì¡°
- **ì˜ˆë°©**: ë½ í”„ë¡œíŒŒì¼ë§, ë™ì‹œì„± ì„¤ê³„

### 4. ê³µí†µ ëŒ€ì‘ ì›ì¹™
- **ì¦‰ì‹œ ê²©ë¦¬**: ë¬¸ì œ ì»´í¬ë„ŒíŠ¸ ë¶„ë¦¬
- **ì ì§„ì  ë³µêµ¬**: ë‹¨ê³„ë³„ íŠ¸ë˜í”½ ì¦ê°€
- **ê·¼ë³¸ ì›ì¸ ë¶„ì„**: 5 Whys ê¸°ë²•
- **ì§€ì†ì  ê°œì„ **: í”Œë ˆì´ë¶ ì—…ë°ì´íŠ¸

## ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ ë¬¸ì„œì—ì„œëŠ” **ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ ì‚¬ë¡€**ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤:
- **[scaling_disasters.md](scaling_disasters.md)** - ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ì™€ í•´ê²°

---

**"ì¥ì• ëŠ” ë°˜ë“œì‹œ ì˜¨ë‹¤ - ì¤‘ìš”í•œ ê²ƒì€ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ê°ì§€í•˜ê³  ë³µêµ¬í•˜ëŠ”ê°€"**